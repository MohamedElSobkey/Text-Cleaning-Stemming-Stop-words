{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP9lSNfjV/cuuacUe6SCFrO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedElSobkey/Text-Cleaning-Stemming-Stop-words/blob/main/Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aT_N6QhSlos"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.porter import *\n",
        "p_stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['run','runner','running','ran','runs','easily','fairly']\n",
        "\n",
        "for word in words:\n",
        "    print(word+' --> '+p_stemmer.stem(word))"
      ],
      "metadata": {
        "id": "q07jV4eESrlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "s_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "words = ['run','runner','running','ran','runs','easily','fairly']\n",
        "\n",
        "for word in words:\n",
        "    print(word+' --> '+s_stemmer.stem(word))"
      ],
      "metadata": {
        "id": "tUdCp0BYSxvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['generous','generation','generously','generate']\n",
        "\n",
        "for word in words:\n",
        "    print(word+' --> '+s_stemmer.stem(word))\n",
        "    print(word+' --> '+p_stemmer.stem(word))\n",
        "    print('---------------------------------------')\n"
      ],
      "metadata": {
        "id": "W6_BennAS0gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer , LancasterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "ls =  LancasterStemmer()"
      ],
      "metadata": {
        "id": "QuX2AmPSS3O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"is\",\"was\",\"be\",\"been\",\"are\",\"were\"]"
      ],
      "metadata": {
        "id": "lqvIarKRTHw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "    print(f'Word  {w}    has setmming      {ps.stem(w)}')"
      ],
      "metadata": {
        "id": "1OOjr2exTKcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "    print(f'Word  {w}    has setmming      {ls.stem(w)}')"
      ],
      "metadata": {
        "id": "0JlUrQgNTNEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"book\",\"booking\",\"booked\",\"books\",\"booker\",\"bookstore\"]"
      ],
      "metadata": {
        "id": "elay_72vTPVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "    print(f'Word  {w}    has setmming      {ps.stem(w)}')"
      ],
      "metadata": {
        "id": "9BAIYYQUTR_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "    print(f'Word  {w}    has setmming      {ls.stem(w)}')"
      ],
      "metadata": {
        "id": "opqSaOlhTUlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'had you booked the air booking yet ? if not try to book it ASAP since booking will be out of books'"
      ],
      "metadata": {
        "id": "1jKYf6yfTXgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "\n",
        "for w in words:\n",
        "    print(f'Word  {w}    has setmming      {ps.stem(w)}')"
      ],
      "metadata": {
        "id": "mVAkker9Tama"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(sentence)\n",
        "\n",
        "for w in words:\n",
        "    print(f'Word  {w}    has setmming      {ls.stem(w)}')"
      ],
      "metadata": {
        "id": "2e1I7-LiTdJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\",\"stabil\",\"destabilize\",\"misunderstanding\",\n",
        "             \"railroad\",\"moonlight\",\"football\"]\n",
        "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}\".format(word,ps.stem(word),ls.stem(word)))"
      ],
      "metadata": {
        "id": "P-E-ramzTkIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "2vfJ0v_aTpkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"cats\",\"cacti\",\"radii\",\"feet\",\"speech\",'runner']\n",
        "\n",
        "for word in words :\n",
        "    print(lemmatizer.lemmatize(word))\n"
      ],
      "metadata": {
        "id": "g3odEEAETsMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatizer.lemmatize(\"meeting\", \"n\"))\n",
        "print(lemmatizer.lemmatize(\"meeting\",'v'))"
      ],
      "metadata": {
        "id": "Q0MJBHLXTtCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "id": "K0oKXEGyTyMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word, pos=\"v\")))"
      ],
      "metadata": {
        "id": "734RL8v6TzqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"is\",\"was\",\"be\",\"been\",\"are\",\"were\"]\n",
        "\n",
        "for word in words :\n",
        "    print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "id": "FF_cjjWbT4U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"is\",\"was\",\"be\",\"been\",\"are\",\"were\"]\n",
        "for word in words :\n",
        "    print(lemmatizer.lemmatize(word,'v'))"
      ],
      "metadata": {
        "id": "Iw5hRNeJT9QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"feet\",\"radii\",\"men\",\"children\",\"carpenter\",\"fighter\"]\n",
        "for word in words :\n",
        "    print(lemmatizer.lemmatize(word,'n'))"
      ],
      "metadata": {
        "id": "4VjafAghT_eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['الجري','تجري','يجرون','جري','يجري']\n",
        "for word in words:\n",
        "    print(word+' --> '+p_stemmer.stem(word))"
      ],
      "metadata": {
        "id": "6dFRSFfTUEds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "s_stemmer = SnowballStemmer(language='arabic')\n",
        "\n",
        "words = ['الجري','تجري','يجرون','جري','يجري']\n",
        "for word in words:\n",
        "    print(word+' --> '+s_stemmer.stem(word))"
      ],
      "metadata": {
        "id": "GZWyqULFUHFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['الجري','تجري','يجرون','جري','يجري']\n",
        "\n",
        "for word in words:\n",
        "    print(word+' --> '+s_stemmer.stem(word))"
      ],
      "metadata": {
        "id": "2EmlnTqtUJhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer , LancasterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "ls =  LancasterStemmer()"
      ],
      "metadata": {
        "id": "bmf4N9-PUM0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['الجري','تجري','يجرون','جري','يجري']"
      ],
      "metadata": {
        "id": "RsEVRDsmUPrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "    print(ps.stem(w))"
      ],
      "metadata": {
        "id": "-OaZZwGiUULM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "    print(ls.stem(w))"
      ],
      "metadata": {
        "id": "kajgTx6lUU7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['الجري','تجري','يجرون','جري','يجري']\n",
        "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
        "for word in words:\n",
        "    print(\"{0:20}{1:20}{2:20}\".format(word,ps.stem(word),ls.stem(word)))"
      ],
      "metadata": {
        "id": "fnmce3JVUXjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "PWZf9kJ1UcED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['الجري','تجري','يجرون','جري','يجري']\n",
        "\n",
        "for word in words :\n",
        "    print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "id": "HKO3RQQDUdLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "StemDict = {'run':['run','runs','running','runner','rerun','ran'],\n",
        "            'book':['book','books','booking','booker','rebook'],\n",
        "           'عمل' : ['يعمل','عامل','يعملون','عمال','العمال'] }\n",
        "\n",
        "# T ='he went for running last night as he love ran and he always runs at night , so he can book the booking from the booker'\n",
        "T = 'ذهب محمد مع العمال كي يعملون في المصنع لانه يعمل  عامل مع عمال آخرين'\n",
        "\n",
        "\n",
        "NewT = []\n",
        "for word in T.split() :\n",
        "  NewWord = ''\n",
        "  Found = False\n",
        "  for k in StemDict.keys() :\n",
        "    if word.lower() in StemDict[k] :\n",
        "      NewWord = k\n",
        "      Found = True\n",
        "  if not Found :\n",
        "    NewWord = word\n",
        "  NewT.append(NewWord)\n",
        "' '.join(NewT)"
      ],
      "metadata": {
        "id": "70U4P2NvUhns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}